Activation Function|激活函数|[[1]](https://www.jiqizhixin.com/articles/75832471-bf67-4450-9173-ada016694ee8) / [[2]](https://www.jiqizhixin.com/articles/343a4328-2915-4b20-a770-9e8bc74dfc1a)
Accumulated error backpropagation|累积误差逆传播|[1]
Adaptive Resonance Theory/ART|自适应谐振理论|[1]
Addictive model|加性学习|[1]
Adversarial Networks|对抗网络|[1]
Affine Layer|仿射层|[1]
Affinity matrix|亲和矩阵|[1]
Agent|智能体|[[1]](https://www.jiqizhixin.com/articles/83490ca4-3bb9-40fa-9306-366902430ade) / [[2]](https://www.jiqizhixin.com/articles/c3cfa8fe-3f1e-49bc-ae5e-0ea0720c0dd3) / [[3]](https://www.jiqizhixin.com/articles/3b85b031-aabe-4814-9da2-708da822c15e) / [[4]](https://www.jiqizhixin.com/articles/e8ebba0d-0c7e-4a95-9428-b17513e950ef)
Algorithm|算法|[[1]](https://www.jiqizhixin.com/articles/99633338-62ff-460e-b313-0ab7a38d6592) / [[2]](https://www.jiqizhixin.com/articles/90a896ca-c170-4cb9-b388-e27972d9888e) / [[3]](https://www.jiqizhixin.com/articles/66d2b476-1f96-452a-8bfc-1fbc2104e935)
Alpha-beta pruning|α-β剪枝|[1]
Anomaly detection|异常检测|[1]
Approximation|近似|[1]
Area Under ROC Curve／AUC|Roc 曲线下面积|[1]
Artificial General Intelligence/AGI|通用人工智能|[1]
Artificial Intelligence/AI|人工智能|[[1]](https://www.jiqizhixin.com/articles/6c4d3c08-7da7-4eb3-94e4-39a1c62f8f14) / [[2]](https://www.jiqizhixin.com/articles/becd2fae-251d-4a7b-9138-0c23abc37bec) / [[3]](https://www.jiqizhixin.com/articles/384306f4-c2c3-4e31-b35f-42b33b605d53)
Association analysis|关联分析|[1]
Attention mechanism|注意力机制|[[1]](https://www.jiqizhixin.com/articles/826db510-639e-4e3d-9c1e-65e2a5297ab2) / [[2]](https://www.jiqizhixin.com/articles/dc109d2e-b297-4017-807d-705900e4923e) / [[3]](https://www.jiqizhixin.com/articles/5be2c12a-0e58-45fe-8478-26528b14cced)
Attribute conditional independence assumption |属性条件独立性假设|[1]
Attribute space|属性空间|[1]
Attribute value|属性值|[1]
Autoencoder|自编码器|[[1]](https://www.jiqizhixin.com/articles/fa8b9e4a-6c75-403c-880c-9e695d0280c8)
Automatic speech recognition/ASR|自动语音识别|[1]
Automatic summarization|自动摘要|[1]
Average gradient|平均梯度|[1]
Average-Pooling|平均池化|[1]
Backpropagation/BP|反向传播|[[1]](https://www.jiqizhixin.com/articles/2533c5a5-af09-41c0-830a-7e075ad8ccd7)
Backpropagation Through Time|通过时间的反向传播|[1]
Base learner|基学习器|[1]
Base learning algorithm|基学习算法|[1]
Batch Normalization/BN|批量归一化|[1]
Bayes decision rule |贝叶斯判定准则|[1]
Bayes Model Averaging／BMA|贝叶斯模型平均|[1]
Bayes optimal classifier|贝叶斯最优分类器|[1]
Bayesian decision theory|贝叶斯决策论|[1]
Bayes decision rule|贝叶斯判定准则|[1]
Bayes Model Averaging／BMA|贝叶斯模型平均|[1]
Bayes optimal classifier|贝叶斯最优分类器|[1]
Bayesian decision theory|贝叶斯决策论|[1]
Bayesian network|贝叶斯网络|[1]
Between-class scatter matrix|类间散度矩阵|[1]
Bias|偏置 / 偏差|[1]
Bias-variance decomposition|偏差-方差分解|[1]
Bias-Variance Dilemma|偏差 - 方差困境|[1]
Bi-directional Long-Short Term Memory/Bi-LSTM|双向长短期记忆|[1]
Binary classification|二分类|[1]
Binomial test|二项检验|[1]
Bi-partition|二分法|[1]
Boltzmann machine|玻尔兹曼机|[1]
Bootstrap sampling|自助采样法 可重复采样 有放回采样|[1]
Bootstrapping|自助法|[1]
Break-Event Point／BEP|平衡点|[1]
Calibration|校准|[1]
Cascade-Correlation|级联相关|[1]
Categorical attribute|离散属性|[1]
Class-conditional probability|类条件概率|[1]
Classification and regression tree/CART|分类与回归树|[1]
Classifier|分类器|[1]
Class-imbalance|类别不平衡|[1]
Closed-form|闭式|[1]
Cluster|簇/类/集群|[1]
Cluster analysis|聚类分析|[1]
Clustering|聚类|[1]
Clustering ensemble|聚类集成|[1]
Co-adapting|共适应|[1]
Coding matrix|编码矩阵|[1]
COLT|国际学习理论会议|[1]
Committee-based learning	|基于委员会的学习|[1]
Competitive learning	|竞争型学习|[1]
Component learner	|组件学习器|[1]
Comprehensibility	|可解释性|[1]
Computation Cost|	计算成本|[1]
Computational Linguistics|	计算语言学|[1]
Computer vision|	计算机视觉|[1]
Concept drift|	概念漂移|[1]
Concept Learning System /CLS|	概念学习系统|[1]
Conditional entropy|条件熵|[1]
Conditional mutual information|	条件互信息|[1]
Conditional Probability Table／CPT|	条件概率表|[1]
Conditional random field/CRF|	条件随机场|[1]
Conditional risk |	条件风险|[1]
Confidence|	置信度|[1]
Confusion matrix	|混淆矩阵|[1]
Connection weight	|连接权|[1]
Connectionism	|连结主义|[1]
Consistency	|一致性／相合性|[1]
Contingency table	|列联表|[1]
Continuous attribute	|连续属性|[1]
Convergence|	收敛|[1]
Conversational agent	|会话智能体|[1]
Convex quadratic programming 	|凸二次规划|[1]
Convexity|	凸性|[1]
Convolutional neural network/CNN|	卷积神经网络|[1]
Co-occurrence	|同现|[1]
Correlation coefficient	|相关系数|[1]
Cosine similarity|余弦相似度|[1]
Cost curve	|成本曲线|[1]
Cost Function	|成本函数|[1]
Cost matrix	|成本矩阵|[1]
Cost-sensitive	|成本敏感|[1]
Cross entropy|	交叉熵|[1]
Cross validation	|交叉验证|[1]
Crowdsourcing	|众包|[1]
Curse of dimensionality|维度灾难|[1]
Cut point	|截断点|[1]
Cutting plane algorithm |	割平面法|[1]
Data mining	|数据挖掘|[1]
Data set	|数据集|[1]
Decision Boundary	|决策边界|[1]
Decision stump|	决策树桩|[1]
Decision tree	|决策树／判定树|[1]
Deduction	|演绎|[1]
Deep Belief Network	|深度信念网络|[1]
Deep Convolutional Generative Adversarial Network/DCGAN|	深度卷积生成对抗网络|[1]
Deep learning|	深度学习|[1]
Deep neural network/DNN|	深度神经网络|[1]
Deep Q-Learning	|深度 Q 学习|[1]
Deep Q-Network	|深度 Q 网络|[1]
Density estimation 	|密度估计|[1]
Density-based clustering|密度聚类|[1]
Differentiable neural computer|	可微分神经计算机|[1]
Dimensionality reduction algorithm|	降维算法|[1]
Directed edge|有向边|[1]
Disagreement measure	|不合度量|[1]
Discriminative model	|判别模型|[1]
Discriminator|	判别器|[1]
Distance measure	|距离度量|[1]
Distance metric learning|距离度量学习|[1]
distance metric learning|	距离度量学习|[1]
Distribution|	分布|[1]
Divergence|	散度|[1]
Diversity measure	|多样性度量／差异性度量|[1]
Domain adaption	|领域自适应|[1]
Downsampling	|下采样|[1]
D-separation /Directed separation|有向分离|[1]
Dual problem |	对偶问题|[1]
Dummy node	|哑结点|[1]
Dynamic Fusion	|动态融合|[1]
Dynamic programming|动态规划|[1]
Eigenvalue decomposition|特征值分解|[1]
Embedding	|嵌入|[1]
Emotional analysis	|情绪分析|[1]
Empirical conditional entropy|经验条件熵|[1]
Empirical entropy|经验熵|[1]
Empirical error|	经验误差|[1]
Empirical risk	|经验风险|[1]
End-to-End	|端到端|[1]
Energy-based model	|基于能量的模型|[1]
Ensemble learning|	集成学习|[1]
Ensemble pruning	|集成修剪|[1]
Error Correcting Output Codes／ECOC	|纠错输出码|[1]
Error rate|错误率|[1]
Error-ambiguity decomposition|	误差-分歧分解|[1]
Euclidean distance|	欧氏距离|[1]
Evolutionary computation |演化计算|[1]
Expectation-Maximization/EM|	期望最大化|[1]
Expected loss |期望损失|[1]
Exploding Gradient Problem|	梯度爆炸问题|[1]
Exponential loss function |	指数损失函数|[1]
Extreme Learning Machine/ELM|超限学习机|[1]
Factorization|因子分解|[1]
False negative	|假负类|[1]
False positive|	假正类|[1]
False Positive Rate/FPR	|假正例率|[1]
Feature engineering	|特征工程|[1]
Feature selection|	特征选择|[1]
Feature vector|	特征向量|[1]
Featured Learning	|特征学习|[1]
Feedforward Neural Networks/FNN|前馈神经网络|[1]
Fine-tuning	|微调|[1]
Flipping output	|翻转法|[1]
Fluctuation	|震荡|[1]
Forward stagewise algorithm|前向分步算法|[1]
Frequentist	|频率主义学派|[1]
Full-rank matrix|满秩矩阵|[1]
Functional neuron|功能神经元|[1]
Gain ratio|增益率|[1]
Game theory	|博弈论|[1]
Gaussian kernel function|高斯核函数|[1]
Gaussian Mixture Model	|高斯混合模型|[1]
General Problem Solving	|通用问题求解|[1]
Generalization|	泛化|[1]
Generalization error|	泛化误差|[1]
Generalization error bound|泛化误差上界|[1]
Generalized Lagrange function|广义拉格朗日函数|[1]
Generalized linear model	|广义线性模型|[1]
Generalized Rayleigh quotient	|广义瑞利商|[1]
Generative Adversarial Networks/GAN|	生成对抗网络|[1]
Generative Model	|生成模型|[1]
Generator	|生成器|[1]
Genetic Algorithm/GA|遗传算法|[1]
Gibbs sampling|	吉布斯采样|[1]
Gini index|基尼指数|[1]
Global minimum	|全局最小|[1]
Global Optimization|	全局优化|[1]
Gradient boosting tree|梯度提升树|[1]
Gradient Descent|	梯度下降|[1]
Graph theory	|图论|[1]
Ground-truth	|真相／真实|[1]
Hard  margin |硬间隔|[1]
Hard voting|硬投票|[1]
Harmonic mean	|调和平均|[1]
Hesse matrix|海赛矩阵|[1]
Hidden dynamic model|隐动态模型|[1]
Hidden layer|隐藏层|[1]
Hidden Markov Model/HMM|隐马尔可夫模型|[1]
Hierarchical clustering|层次聚类|[1]
Hilbert space|希尔伯特空间|[1]
Hinge loss function|合页损失函数|[1]
Hold-out|留出法|[1]
Homogeneous|同质|[1]
Hybrid computing|混合计算|[1]
Hyperparameter|超参数|[1]
Hypothesis|假设|[1]
Hypothesis test|假设检验|[1]
ICML|	国际机器学习会议|[1]
Improved iterative scaling/IIS|改进的迭代尺度法|[1]
Incremental learning	|增量学习|[1]
Independent and identically distributed/i.i.d.|	独立同分布|[1]
Independent Component Analysis/ICA|	独立成分分析|[1]
Indicator function|指示函数|[1]
Individual learner	|个体学习器|[1]
Induction	|归纳|[1]
Inductive bias	|归纳偏好|[1]
Inductive learning|	归纳学习|[1]
Inductive Logic Programming／ILP	|归纳逻辑程序设计|[1]
Information entropy	|信息熵|[1]
Information gain|	信息增益|[1]
Input layer|	输入层|[1]
Insensitive loss	|不敏感损失|[1]
Inter-cluster similarity |	簇间相似度|[1]
International Conference for Machine Learning/ICML|	国际机器学习大会|[1]
Intra-cluster similarity|	簇内相似度|[1]
Intrinsic value	|固有值|[1]
Isometric Mapping/Isomap|等度量映射|[1]
Isotonic regression	|等分回归|[1]
Iterative Dichotomiser	|迭代二分器|[1]
Jensen-Shannon Divergence/JSD|JS 散度|[1]
Kernel method|	核方法|[1]
Kernel trick|	核技巧|[1]
Kernelized Linear Discriminant Analysis／KLDA |	核线性判别分析|[1]
K-fold cross validation	|k 折交叉验证／k 倍交叉验证|[1]
K-Means Clustering	|K - 均值聚类|[1]
K-Nearest Neighbours Algorithm/KNN|	K近邻算法|[1]
Knowledge base|知识库|[1]
Knowledge Representation|	知识表征|[1]
Label space|标记空间|[1]
Lagrange duality|拉格朗日对偶性|[1]
Lagrange multiplier|拉格朗日乘子|[1]
Laplace smoothing|拉普拉斯平滑|[1]
Laplacian correction|拉普拉斯修正|[1]
Latent Dirichlet Allocation|隐狄利克雷分布|[1]
Latent semantic analysis|潜在语义分析|[1]
Latent variable|隐变量|[1]
Lazy learning |懒惰学习|[1]
Learner|	学习器|[1]
Learning by analogy|	类比学习|[1]
Learning rate	|学习率|[1]
Learning Vector Quantization/LVQ	|学习向量量化|[1]
Least squares regression tree|最小二乘回归树|[1]
Leave-One-Out/LOO	|留一法|[1]
Linear Discriminant Analysis／LDA	|线性判别|[1]
Linear model|	线性模型|[1]
Linear Regression|	线性回归|[1]
Link function|	联系函数|[1]
Local Markov property|局部马尔可夫性|[1]
Local minimum	|局部最小|[1]
Log likelihood|	对数似然|[1]
Log odds／logit|	对数几率|[1]
Logistic Regression|Logistic 回归|[1]
Log-likelihood|	对数似然|[1]
Log-linear regression|	对数线性回归|[1]
Long-Short Term Memory/LSTM|	长短期记忆|[1]
Loss function|	损失函数|[1]
Machine translation/MT|	机器翻译|[1]
Macron-P	|宏查准率|[1]
Macron-R	|宏查全率|[1]
Majority voting|	绝对多数投票法|[1]
Manifold assumption|流形假设|[1]
Manifold learning|流形学习|[1]
Margin theory	|间隔理论|[1]
Marginal distribution|边际分布|[1]
Marginal independence 	|边际独立性|[1]
Marginalization 	|边际化|[1]
Markov Chain Monte Carlo/MCMC|马尔可夫链蒙特卡罗方法|[1]
Markov Random Field|马尔可夫随机场|[1]
Maximal clique|最大团|[1]
Maximum Likelihood Estimation/MLE|	极大似然估计／极大似然法|[1]
Maximum margin	|最大间隔|[1]
Maximum weighted spanning tree|	最大带权生成树|[1]
Max-Pooling	|最大池化|[1]
Mean squared error	|均方误差|[1]
Meta-learner|	元学习器|[1]
Metric learning|度量学习|[1]
Micro-P	|微查准率|[1]
Micro-R	|微查全率|[1]
Minimal  Description Length/MDL|	最小描述长度|[1]
Minimax game	|极小极大博弈|[1]
Misclassification cost|	误分类成本|[1]
Mixture of experts|	混合专家|[1]
Momentum	|动量|[1]
Moral graph	|道德图／端正图|[1]
Multi-class classification	|多分类|[1]
Multi-document summarization	|多文档摘要|[1]
Multi-layer feedforward neural networks|	多层前馈神经网络|[1]
Multilayer Perceptron/MLP|	多层感知器|[1]
Multimodal learning|	多模态学习|[1]
Multiple Dimensional Scaling|多维缩放|[1]
Multiple linear regression|	多元线性回归|[1]
Multi-response Linear Regression ／MLR	|多响应线性回归|[1]
Mutual information|互信息|[1]
Naive bayes|朴素贝叶斯|[1]
Naive Bayes Classifier|朴素贝叶斯分类器|[1]
Named entity recognition|命名实体识别|[1]
Nash equilibrium|纳什均衡|[1]
Natural language generation/NLG|自然语言生成|[1]
Natural language processing|自然语言处理|[1]
Negative class|负类|[1]
Negative correlation|负相关法|[1]
Negative Log Likelihood|负对数似然|[1]
Neighbourhood Component Analysis/NCA|近邻成分分析|[1]
Neural Machine Translation|神经机器翻译|[1]
Neural Turing Machine|神经图灵机|[1]
Newton method|牛顿法|[1]
NIPS|国际神经信息处理系统会议|[1]
No Free Lunch Theorem／NFL|没有免费的午餐定理|[1]
Noise-contrastive estimation|噪音对比估计|[1]
Nominal attribute|列名属性|[1]
Non-convex optimization|非凸优化|[1]
Nonlinear model|非线性模型|[1]
Non-metric distance|非度量距离|[1]
Non-negative matrix factorization|非负矩阵分解|[1]
Non-ordinal attribute|无序属性|[1]
Non-Saturating Game|非饱和博弈|[1]
Norm|范数|[1]
Normalization|归一化|[1]
Nuclear norm|核范数|[1]
Numerical attribute|数值属性|[1]
Objective function|目标函数|[1]
Oblique decision tree|斜决策树|[1]
Occam's razor|奥卡姆剃刀|[1]
Odds|几率|[1]
Off-Policy|离策略|[1]
One shot learning|一次性学习|[1]
One-Dependent Estimator／ODE|独依赖估计|[1]
On-Policy|在策略|[1]
Ordinal attribute|有序属性|[1]
Out-of-bag estimate	|包外估计|[1]
Output layer|输出层|[1]
Output smearing|输出调制法|[1]
Overfitting	|过拟合／过配|[1]
Oversampling|过采样|[1]
Paired t-test|成对 t 检验|[1]
Pairwise|成对型|[1]
Pairwise Markov property|成对马尔可夫性|[1]
Parameter|参数|[1]
Parameter estimation|参数估计|[1]
Parameter tuning|调参|[1]
Parse tree|解析树|[1]
Particle Swarm Optimization/PSO|粒子群优化算法|[1]
Part-of-speech tagging|词性标注|[1]
Perceptron|感知机|[1]
Performance measure|性能度量|[1]
Plug and Play Generative Network|即插即用生成网络|[1]
Plurality voting|相对多数投票法|[1]
Polarity detection|极性检测|[1]
Polynomial kernel function|多项式核函数|[1]
Pooling|池化|[1]
Positive class|正类|[1]
Positive definite matrix|正定矩阵|[1]
Post-hoc test|后续检验|[1]
Post-pruning|后剪枝|[1]
potential function|势函数|[1]
Precision|查准率／准确率|[1]
Prepruning|预剪枝|[1]
Principal component analysis/PCA|主成分分析|[1]
Principle of multiple explanations|多释原则|[1]
Prior|先验|[1]
Probability Graphical Model|概率图模型|[1]
Proximal Gradient Descent/PGD|近端梯度下降|[1]
Pruning|剪枝|[1]
Pseudo-label|伪标记|[1]
Quantized Neural Network/QNN|量子化神经网络|[1]
Quantum computer|量子计算机|[1]
Quantum Computing|量子计算|[1]
Quasi Newton method|拟牛顿法|[1]
Radial Basis Function／RBF|径向基函数|[1]
Random Forest Algorithm|随机森林算法|[1]
Random walk|随机漫步 |[1]
Recall|查全率／召回率|[1]
Receiver Operating Characteristic/ROC|受试者工作特征|[1]
Rectified Linear Unit/ReLU|线性修正单元|[1]
Recurrent Neural Network|循环神经网络|[1]
Recursive neural network|递归神经网络|[1]
Reference model|参考模型|[1]
Regression|回归|[1]
Regularization|正则化|[1]
Reinforcement learning/RL|强化学习|[1]
Representation learning|表征学习|[1]
Representer theorem|表示定理|[1]
Reproducing Kernel Hilbert Space /RKHS|再生核希尔伯特空间|[1]
Re-sampling|重采样法|[1]
Rescaling|再缩放|[1]
Residual Mapping|残差映射|[1]
Residual Network|残差网络|[1]
Restricted Boltzmann Machine/RBM|受限玻尔兹曼机|[1]
Restricted Isometry Property/RIP|限定等距性|[1]
Re-weighting|重赋权法|[1]
Robustness|稳健性/鲁棒性|[1]
Root node|根结点|[1]
Rule Engine|规则引擎|[1]
Rule learning|规则学习|[1]
Saddle point|鞍点|[1]
Sample space|样本空间|[1]
Sampling|采样|[1]
Score function|评分函数|[1]
Self-Driving|自动驾驶|[1]
Self-Organizing Map／SOM|自组织映射|[1]
Semi-naive Bayes classifiers|半朴素贝叶斯分类器|[1]
Semi-Supervised Learning|半监督学习|[1]
semi-Supervised Support Vector Machine|半监督支持向量机|[1]
Sentiment analysis|情感分析|[1]
Separating hyperplane|分离超平面|[1]
Sigmoid function|Sigmoid 函数|[1]
Similarity measure|相似度度量|[1]
Simulated annealing|模拟退火|[1]
Simultaneous localization and mapping|同步定位与地图构建|[1]
Singular Value Decomposition|奇异值分解|[1]
Slack variables|松弛变量|[1]
Smoothing|平滑|[1]
Soft margin|软间隔|[1]
Soft margin maximization|软间隔最大化|[1]
Soft voting|软投票|[1]
Sparse representation|稀疏表征|[1]
Sparsity|稀疏性|[1]
Specialization|特化|[1]
Spectral Clustering|谱聚类|[1]
Speech Recognition|语音识别|[1]
Splitting variable|切分变量|[1]
Squashing function|挤压函数|[1]
Stability-plasticity dilemma|可塑性-稳定性困境|[1]
Statistical learning|统计学习|[1]
Status feature function|状态特征函|[1]
Stochastic gradient descent|随机梯度下降|[1]
Stratified sampling|分层采样|[1]
Structural  risk|结构风险|[1]
Structural risk minimization/SRM|结构风险最小化|[1]
Subspace|子空间|[1]
Supervised learning|监督学习／有导师学习|[1]
support vector expansion|支持向量展式|[1]
Support Vector Machine/SVM|支持向量机|[1]
Surrogat loss|替代损失|[1]
Surrogate function|替代函数|[1]
Symbolic learning|符号学习|[1]
Symbolism|符号主义|[1]
Synset|同义词集|[1]
T-Distribution Stochastic Neighbour Embedding/t-SNE|T - 分布随机近邻嵌入|[1]
Tensor|张量|[1]
Tensor Processing Units/TPU|张量处理单元|[1]
The least square method|最小二乘法|[1]
Threshold|阈值|[1]
Threshold logic unit|阈值逻辑单元|[1]
Threshold-moving|阈值移动|[1]
Time Step|时间步骤|[1]
Tokenization|标记化|[1]
Training error|训练误差|[1]
Training instance|训练示例／训练例|[1]
Transductive learning|直推学习|[1]
Transfer learning|迁移学习|[1]
Treebank|树库|[1]
Tria-by-error|试错法|[1]
True negative|真负类|[1]
True positive|真正类|[1]
True Positive Rate/TPR|真正例率|[1]
Turing Machine|图灵机|[1]
Twice-learning|二次学习|[1]
Underfitting	|欠拟合／欠配|[1]
Undersampling	|欠采样|[1]
Understandability	|可理解性|[1]
Unequal cost|	非均等代价|[1]
Unit-step function|	单位阶跃函数|[1]
Univariate decision tree	|单变量决策树|[1]
Unsupervised  learning|	无监督学习／无导师学习|[1]
Unsupervised layer-wise training	|无监督逐层训练|[1]
Upsampling	|上采样|[1]
Vanishing Gradient Problem|梯度消失问题|[1]
Variational inference|变分推断|[1]
VC Theory|VC维理论|[1]
Version space|版本空间|[1]
Viterbi algorithm|维特比算法|[1]
Von Neumann architecture|冯 · 诺伊曼架构|[1]
Weak learner|弱学习器|[1]
Weight|权重|[1]
Weight sharing|	权共享|[1]
Weighted voting|	加权投票法|[1]
Wasserstein GAN/WGAN|	Wasserstein生成对抗网络|[1]
Within-class scatter matrix|	类内散度矩阵|[1]
Word embedding|	词嵌入|[1]
Word sense disambiguation|	词义消歧|[1]
Zero-data learning|零数据学习|[1]
Zero-shot learning|零次学习|[1]
